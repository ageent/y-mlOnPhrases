{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "ImP_21-22_ex11.ipynb",
   "provenance": [],
   "authorship_tag": "ABX9TyNDIr5w0A6UugzXtrPiiTVl"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Initial Preparation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# TensorFlow ≥2.4 is required in this notebook\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.4\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# For changes\n",
    "USER = \"ageent\"\n",
    "REPO = \"y-mlOnPhrases\"\n",
    "X_FILE = \"X.npy\"\n",
    "Y1_FILE = \"Y1.npy\"\n",
    "Y2_FILE = \"Y2.npy\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# to save data or images\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import drive\n",
    "    ROOT_GD = \"/content/drive\"\n",
    "    STORAGE_PATH = ROOT_GD + \"/My Drive/Colab Notebooks/\" + REPO + \"/\"\n",
    "    drive.mount(ROOT_GD)\n",
    "else:   # local host\n",
    "    STORAGE_PATH = \"data/\"\n",
    "\n",
    "def save_data(prefix, file_name, data_frame):\n",
    "    path = STORAGE_PATH + prefix + file_name\n",
    "    data_frame.to_csv(path)\n",
    "\n",
    "def save_pred(file_name, data_frame):\n",
    "    save_data(\"predictions/\", file_name, data_frame)\n",
    "def save_trans_data(file_name, data_frame):\n",
    "    save_data(\"transformed/\", file_name, data_frame)\n",
    "\n",
    "\"\"\"\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(data)\n",
    "save_fig(fig, \"fig_name\")\n",
    "\"\"\"\n",
    "def save_fig(fig, fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = STORAGE_PATH + \"img/\" + fig_id + \".\" + fig_extension\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        fig.tight_layout()\n",
    "    fig.savefig(path, format=fig_extension, dpi=resolution)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zIr8cYS4B10Q",
    "outputId": "b045f083-d0d7-421d-bc9c-1964fe2c3fef"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "n5zKpPBENYap",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get the data\n",
    "def get_github_data(path_to_file):\n",
    "    \"\"\"TODO: maybe need to use requests.\"\"\"\n",
    "    url = \"https://raw.githubusercontent.com/{}/{}/{}\"\\\n",
    "                            .format(USER, REPO, path_to_file)\n",
    "    return np.load(url)\n",
    "\n",
    "def get_localhost_data(file_name):\n",
    "    path = \"data/src/\" + file_name\n",
    "    return np.load(path)\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    PATH_TO_SRC = \"main/data/src/\"\n",
    "    X_DATA = get_github_data(PATH_TO_SRC + X_FILE)\n",
    "    Y1_DATA = get_github_data(PATH_TO_SRC + Y1_FILE)\n",
    "    Y2_DATA = get_github_data(PATH_TO_SRC + Y2_FILE)\n",
    "else:   # local host\n",
    "    X_DATA = get_localhost_data(X_FILE)\n",
    "    Y1_DATA = get_localhost_data(Y1_FILE)\n",
    "    Y2_DATA = get_localhost_data(Y2_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 128)\n",
      "[-0.98200285  5.3519163   0.6241017  -3.7863977  -2.0433748  -1.6433135\n",
      "  5.0111694   0.11501709 -3.3202858   2.2631938   4.487829    3.1017983\n",
      "  3.4887044  -4.942223    6.474518    0.77631605  5.3201113  -5.003155\n",
      " -6.0889516   3.9606059   4.9673815   0.5534823   2.3377123  -3.4211032\n",
      "  5.278324    1.576092   -5.2838745   0.5925345  -1.2432728   1.5591371\n",
      " -1.0380139  -0.1521509   2.4624774   6.4752107  -4.399489   -2.6032155\n",
      "  3.5712152   0.44489035  1.3303515   0.42398357  2.2737198   7.777598\n",
      " -3.3040464  -2.2658207  -7.7937617  -0.6868003   7.5321355   0.5417963\n",
      "  2.423962    7.1077695  -0.6353128   3.4406264  -2.3372521   0.1237992\n",
      "  1.9296596   4.452048    2.1478891  -2.770266   -9.235324   10.521325\n",
      " -8.574103   -3.127737   -5.1270823   5.001681   -2.710712    0.44150203\n",
      " -0.15498942  0.24662127 -0.21252623 -1.7166231  -1.0460446  -5.4344797\n",
      "  2.56957    10.698443   -3.0771906   1.0651661  -0.32124305  5.725385\n",
      "  7.167192    5.156452    5.6941953   6.4998055   6.7241087   4.867395\n",
      "  4.8166933   5.9493546   6.5271215   5.819747    4.9900017   6.3283215\n",
      "  7.1935315   5.8655896   6.8128476   6.5611515   7.1959248   5.8582344\n",
      "  5.560118    6.7187347   5.353525    6.103025    0.99591273 -6.4906607\n",
      " -1.1090117  -4.1813335  -2.039458   -2.27983     4.6208878   3.837874\n",
      "  7.4326015  -2.311741   -1.0066502   2.979867    0.1064807   3.888947\n",
      "  0.89728075  2.5419183  -6.5907764  -0.49537855 -1.0346819   0.15862758\n",
      "  1.8829461   1.5021307   0.15528834  2.6389506  -1.3379864   5.460588\n",
      "  0.80857795 -5.7801805 ]\n"
     ]
    }
   ],
   "source": [
    "print(X_DATA.shape)\n",
    "print(X_DATA[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800,)\n",
      "[1 2 2 0 1 0 2 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(Y1_DATA.shape)\n",
    "print(Y1_DATA[0:10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800,)\n",
      "[ 6. 15. 34. 58. 27. 29. 50. 12.  7. 17.]\n"
     ]
    }
   ],
   "source": [
    "print(Y2_DATA.shape)\n",
    "print(Y2_DATA[0:10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature engineering\n",
    "### Transforming"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "x = X_DATA.copy()\n",
    "y2 = Y2_DATA.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "transformer_y1 = OneHotEncoder()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 1., 0.],\n       [0., 0., 1.],\n       [0., 0., 1.],\n       ...,\n       [1., 0., 0.],\n       [0., 1., 0.],\n       [1., 0., 0.]])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1 = transformer_y1.fit_transform(Y1_DATA[:, np.newaxis]).toarray()\n",
    "y1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Shuffle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(800, 132)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_ = np.hstack([x, y1, y2[:, np.newaxis]])\n",
    "t_.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "np.random.shuffle(t_)\n",
    "x = t_[:, :128].copy()\n",
    "y1 = t_[:, 128:131].copy()\n",
    "y2 = t_[:, 131].copy()\n",
    "%reset_selective -f t_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model selection"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "model1 = keras.models.Sequential()\n",
    "model1.add(keras.layers.Dense(3, activation=\"linear\", use_bias=False, input_shape=[128]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "def classifier_metric():\n",
    "    def cm(y_true, y_pred):\n",
    "        tf.keras.metrics.sparse_categorical_accuracy(y_true[:, :3], y_pred)\n",
    "    return cm\n",
    "\n",
    "def regressor_metric():\n",
    "    def rm(y_true, y_pred):\n",
    "        w_reg = 1 / 3\n",
    "        y_pred_w = y_pred * w_reg\n",
    "        y_pred_reg = tf.reduce_sum(y_pred_w, axis=1)\n",
    "        return tf.metrics.mean_squared_error(y_true[:, 3], y_pred_reg)\n",
    "    return rm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Can not squeeze dim[1], expected a dimension of 1, got 3 [Op:Squeeze]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\CHERN_~1\\AppData\\Local\\Temp/ipykernel_11916/2614985047.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m                        \u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m99\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m                        [0, 99, 0]])\n\u001B[1;32m---> 10\u001B[1;33m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclassifier_metric\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_true_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred_\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mregressor_metric\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_true_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred_\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\CHERN_~1\\AppData\\Local\\Temp/ipykernel_11916/1385056304.py\u001B[0m in \u001B[0;36mcm\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mclassifier_metric\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mcm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m         \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmetrics\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msparse_categorical_accuracy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m:\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mcm\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\chern_000\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 153\u001B[1;33m       \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    154\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    155\u001B[0m       \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\chern_000\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\metrics.py\u001B[0m in \u001B[0;36msparse_categorical_accuracy\u001B[1;34m(y_true, y_pred)\u001B[0m\n\u001B[0;32m   3599\u001B[0m   if (y_true_rank is not None) and (y_pred_rank is not None) and (len(\n\u001B[0;32m   3600\u001B[0m       backend.int_shape(y_true)) == len(backend.int_shape(y_pred))):\n\u001B[1;32m-> 3601\u001B[1;33m     \u001B[0my_true\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msqueeze\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   3602\u001B[0m   \u001B[0my_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcompat\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mv1\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0margmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_pred\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   3603\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mInvalidArgumentError\u001B[0m: Can not squeeze dim[1], expected a dimension of 1, got 3 [Op:Squeeze]"
     ]
    }
   ],
   "source": [
    "# test for metrics\n",
    "y_true_ = tf.constant([[1, 0, 0, 60],\n",
    "                       [0 ,1, 0, 50],\n",
    "                       [0, 0, 1, 20],\n",
    "                       [0, 1, 0, 4]])\n",
    "y_pred_ = tf.constant([[99, 0, 0],\n",
    "                       [0, 99, 0],\n",
    "                       [0, 0, 99],\n",
    "                       [0, 99, 0]])\n",
    "print(classifier_metric()(y_true_, y_pred_))\n",
    "print(regressor_metric()(y_true_, y_pred_))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "def loss1(y_true, y_pred):\n",
    "    \"\"\"y_true have shape (n, 4) and t_pred have shape (n, 3)\"\"\"\n",
    "    y_true_cl = tf.cast(y_true[:, :3], tf.float64)\n",
    "    y_true_reg = tf.cast(y_true[:, 3], tf.float64)\n",
    "\n",
    "    # classification\n",
    "    y_pred_max = tf.reduce_max(y_pred, axis=1)[:, tf.newaxis]\n",
    "    y_pred_norm = y_pred / y_pred_max\n",
    "    ss_cl = tf.square(y_true_cl - y_pred_norm)\n",
    "\n",
    "    # regression\n",
    "    w_reg = 1 / 3\n",
    "    y_pred_w = y_pred * w_reg\n",
    "    y_pred_reg = tf.reduce_sum(y_pred_w, axis=1)\n",
    "    ss_reg = tf.square(y_true_reg - y_pred_reg)\n",
    "\n",
    "    summands = tf.concat([ss_cl, ss_reg[:, tf.newaxis]], 1)\n",
    "    return tf.reduce_sum(summands, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(4,), dtype=float64, numpy=array([3560.11111111, 2466.77777778,  386.77777778,   13.44444444])>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test for loss1\n",
    "y_true_ = tf.constant([[1, 0, 0, 60],\n",
    "                       [0 ,1, 0, 50],\n",
    "                       [0, 0, 1, 20],\n",
    "                       [0, 1, 0, 4]])\n",
    "y_pred_ = tf.constant([[99, 0, 0],\n",
    "                       [0, 99, 0],\n",
    "                       [0, 0, 99],\n",
    "                       [0, 99, 0]])\n",
    "loss1(y_true_, y_pred_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO: do y_true and y_pred with equal dimension\n",
    "model1.compile(loss=loss1,\n",
    "               optimizator=\"nadam\",\n",
    "               metrics=[classifier_metric, regressor_metric])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}